\chapter{Introduction}
Epidemics of infectious diseases are a complex phenomena at the crossing of human behaviour, mobility, host dynamics, environmental factors. 

Modeling provides a formal framework to design and test such approaches. It encompasses uncertainties, transmission dynamics and intervention policies. Depending on its accuracy, a cholera model might be able to reproduce, and even forecast, in time and space the spread of the epidemic.

One of the main goals of epidemiological modeling is to predict the incidence of an ongoing epidemic in order to guide the public health officials in the deployment of life-saving medical supplies and medical staff. Moreover, an accurate model is a viable substitute for an experiment, where stakeholders can test intervention policies and scientific hypothesis on disease dynamics.

A novel use of epidemiological modelling is in the formal design of control policies. \textit{Optimal control} provides a rigorous framework to identify the most effective control measures under a set of operational constraints, in order to minimize an objective function of interest, like disease transmission and death. 

\section{Objectives}

The present thesis, developed within the framework of the Swiss National foundation project ``Optimal
control of intervention strategies for waterborne disease epidemics (SNF 200021--172578)'', aims at developing a decision support system to optimize cholera intervention strategies.

The  primary objective of this thesis is to design and implement an optimal control solver to be coupled with a spatially explicit model of cholera transmission, to compute optimal intervention strategies in real time for health care actors during outbreaks.

Towards an operational forecasting and decision framework, many obstacles must be overcome. The relevance of any control recommendation depends on the accuracy of the model forecasts. Thus, there exists a feedback loop between epidemiological modeling and control implementation. Since process-based epidemiological modeling for cholera is still at its infancy, the refinement of cholera models is essential to produce valid control policies.

The ECHO lab has been working on a spatially-explicit cholera model that has been able to match, and even forecast, the epidemiological curve across a number of settings. During the whole thesis, we will continue to improve this model, and to develop new features, relaxing assumptions and limitations of existing approaches. A major milestone is the creation of an operational forecasting platform for epidemic dynamics, to communicate results in a timely manner.

At the end of the thesis, the final deliverable will be a platform able to provide cholera forecasts and optimal control policies in quasi real time, to exploit the full potential of state-of-the-art spatially explicit cholera models.





\section{Thesis aim and outline}
This thesis was initially focused on cholera, a diareal disease that affects the poorest of the poor. Cholera . Part I of this thesis will present a model-comparison study of the influence of intra-seasonal rainfall events. The COVID-19 pandemic changed the initial plan of optimal control for cholera, hence the most recent part of this work is dedicated to COVID. Part II wil

The construction of such a framework is the object of the present thesis. Building on the laboratory of Ecohydrology at EPFL (ECHO lab in the following) expertise on waterborne disease modeling, optimal control of cholera epidemic is a step forward in the ability for scientists to help policy makers in reducing the global cholera burden.


%The thesis aims at answering the following questions:
%\begin{itemize}
%    \item For a given setup, with operational constraints, what is the optimal way of %allocating control resources to minimize the impact of a cholera outbreak ?
%    \item Do general rules for intervention exists ? In this cases, what are these rules ?
%    \item How do we should allocate surveillance measure in order to best detect upcoming %outbreaks ?
%\end{itemize}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Materials and methods} %(Computational epidemiomology or Infectious Disease Modeling

\section{Infectious Diseases Epidemics} %as a phenomena)
Infect



\section{Modeling of Epidemics}
The ultimate goal being  the forecasting and estimating the propagation of uncertainties from the observable past to the future. Alongside, modeling helps us to understand the different processes of the cholera life cycle. As a substitute for physical experiments, different mechanistic pathways can be compared by benchmarking them against the reproduction of reported cases. 

Models may have only one spatial dimension or may consider the spatial spread of the epidemic across several nodes. Spatially-explicit mathematical models provide key insights into the course of an ongoing epidemic, where transmission is heterogeneous in space and time.

% (Bayesian philosophy, data, representation of reality) sochastic/determistic Modeling of epidemics (uncertainties, social factors, heterogeneities)



\subsection{Data}
%data on health
Model makes use of epidemiological data: reported cases, severity of outcomes, serology survey. 

Covariates or input data range from rainfall and temperature, human mobility.

Information and prior on



\subsection{Model design}

"Since all models are wrong the scientist must be alert to what is importantly wrong. It is inappropriate to be concerned about mice when there are tigers abroad."\cite{Box:ScienceStatistics:1976}.




The cornstone of epidemiological modeling is the compartmental model. Individuals belongs to compartiments who caraterize their stage with respect to the disease. The seminal work has introduced compartiments for Susceptible, Infected, Recovered. The SIR model, first introduced first by Kermack and McKendrick\cite{Kermack:ContributionMathematicalTheory:1927}.s

An Exposed compartiment may be added 
Compartimental + spatially explicit
\subsection{Inference and calibration} 
Model parameters in the SIRB cholera models represent physical rates. However, in the literature there is no consensus on their values or on their  probability distribution. Numerical calibration is therefore required to assess their value in any particular application. Parameter identifiability is one of the major problems during the calibration of SIR-like epidemiological models. This is mainly due to the impossibility to directly measure the exact figures of individual infections in each compartment, the uncertainty associated to epidemiological data and the net effect of possible model over-parametrization. Calibration thus often results in combination of parameters that produce almost identical fits, termed equifinality\footnote{For a cholera example, Eisenberg et al. (\fullcite{eisenberg_identifiability_2013}) highlighted that the presence of uncertain measurements might generate strongly correlated parameters, which cannot be unambiguously  identified.}.




 Filtering
\subsection{Evaluation}
We may evaluate thte model predictive accuracy
\subsection{Model Selection}
% DONE w.r.t gelman
% TODO w.r.t McElreath
For inference or prediction, several candidates models may be devised for same data and process. Model selection aims at finding the \textit{best} (set of) model(s) for the task at hand. In the perspective of identifying the data-generating process a consistent model selection criteria is warranted\parencite{Hoge:PrimerModelSelection:2018}.  On way of doing that is to compare their predictive accuracy. Sometime it can be computed in way that is tailored to the application and embed the benefits and cost of predictiding data with the model \footnote{i.e for weather, predicting rain when there's none is considered lower cost than predicting sun when it rains}, or we may resort to generic rules.
The log-likelyhood (or log predictive density), $\Pr(data | \boldsymbol\theta$  is often used. Note by using the likelyhood instead of the posterior, we don't depends on the priors but just on the data model (but as the prior influence $\boldsymbol\theta$, it does affects the calculation of the predictive density). The log predictive accuracy as a scoring function i related to information theory, and to the Kull-back Leibler information.
Unfortunatly, the hypothetical gold standard that is the expected log predictive density for new datapoints is out-of-reach in most of our problems. However we can compute an optimistic\footnote{optimistic because we have used the same as we used to calibrate our model. Generaly, out-of-sample predictions (i.e for a new datapoint) will be less accurate that what this within-sample accuraty}estimation, computing the log-poinwise predictive density of our model to the fitted data. For $s$ posterior samples and our $n$ datapoints, we have
\begin{equation}
	EQUN 7.4 \ref{eq:llik}
\end{equation}
To approxmimate the true out-of sample predictive accurcy we can 
\begin{itemize}
	\item Fit the model to a part (a fold) of the available data and compute it's predictive accucary on the other part. This is called \emph{cross-validation}, and a common version of it is leave-one-out cross validation, where, in turn we leave out just one datapoint for calibration and compute the predictive accuacy on it. This is computationally expensive, as we need to perform $n$ calibrations.
	\item Hence many methods where designed to unbias the within-sample accuracy and approximate the results of cross-validation, usually by substracting  a correction made of some functions for the effective parameters being fit. We find here an alphabet of information criterions (ICs):  Akaike (AIC), Deviance  (DIC), Watanabe-Akaike (WAIC)\footnote{AIC takes into consideration the number of parameters while DCI, WAIC compute aneffective number of parameters that takes into account the observed data. While the means are different,  all estimating the same thing: the expected out-of-sample deviance associated with a model. BIC, introduced futher, is notably different because as its goal is different: estimating the marginal probabability of the the data under the model and is related to the bayes factor, see below.} being notable.
\end{itemize}
And both of these methods penalize overfitting (more paramters always improve fit), as they assess the generality of the model.




. Within each family of deterministic and stochastic models, we employ both Bayesian (Bayes Factors, BFs) and frequentist (likelihood ratio tests) model comparison techniques. 

For the deterministic model, calibrated using Bayesian inference, we use the Bayes Factors (BFs). Bayes Factors are a controversial\footnote{See the great debate in Sociological Methodology:\fullcite{Raftery:BayesianModelSelection:1995} and counter arguments\fullcite{Gelman:AvoidingModelSelection:1995}} method that we use in our XXX chapter to compare discrete choices of model.

We have a model selection problem. Given the observation of data $D$, we have to choose between two models $\mathcal{M}_i$ and $\mathcal{M}_j$ each parametrized by parameters sets $\theta_i$ and $\theta_j$.

\paragraph{Bayes Factor}  The goal might be to choose on of the model or to averates discrete set of probabilites. The aim is to link the posteriors and prior odd ratios:
\begin{equation}
    \overbrace{\frac{\mathbb{P}(\mathcal{M}_i|D)}{\mathbb{P}(\mathcal{M}_j|D)}}^{\text{posterior odd ratio}} =
    \overbrace{BF_{i,j}}^\text{Bayes factor} \times  \overbrace{\frac{\mathbb{P}(\mathcal{M}_i)}{\mathbb{P}(\mathcal{M}_j)}}^{\text{prior odd ratio}}
\end{equation}
 where $\mathbb{P}(\mathcal{M}|D)$ represents the posterior probability of a model $\mathcal{M}$ is the probability of the model given the data
Given Bayes theorem, we have
\begin{equation}
  BF_{i,j} = \frac{\mathbb{P}(D|\mathcal{M}_i)}{\mathbb{P}(D|\mathcal{M}_j)}
\end{equation}
 where $\mathbb{P}(D|\mathcal{M})$ is  the \textit{model evidence}, or marginal likelihood of model $\mathcal{M}$ \parencite{Aitkin:PosteriorBayesFactors:1991}. It represents the probability of the data given the model, not assuming any particular model parameters (because parameter $\theta$ have been \textit{marginalized (integrated) out}), and is given by a (difficult to compute) integral:
 \begin{equation}
\mathbb{P}(D|\mathcal{M}) = \int_\theta \mathbb{P}(D|\theta,M) \mathbb{P}(\theta|M) d\theta .
\end{equation} 
 The model evidence can be directly computed using the output the mcmc algorithm as the harmonic mean of each model likelihood over the posterior distribution of the parameters. As described by\textcite{Weinberg:ComputingBayesFactor:2012}, if one can draw $N$ samples from the posteriors of the parameters, $\theta^{(i)} \sim \mathbb{P}(\theta|\mathcal{M}, D)$, a Monte Carlo estimate of the model evidence is given by:
 \begin{equation}
 	\mathbb{P}(D|\mathcal{M}) \approx {\left[ \frac{1}{N} \sum_{i=1}^N \frac{1}{\underbrace{\mathbb{P}(D|\theta^{(i)})}_{\text{likelyhood of } \theta^{(i)}}} \right]^{-1}}, 
 \end{equation}
which can then be used to derive BFs (see \parencite{Raftery:EstimatingIntegratedLikelihood:2007} for a discussion on the possible numerical issues involved in this approximation.
%\end{multicols}

%\begin{multicols}{2}
 \paragraph{Bayesian Information Criterion} On the other hand, model evidence of the stochastic model was evaluated using the Bayesian Information Criterion (BIC) computed at the Maximum Likelihood Estimate (MLE) resulting from the multiple itertated filtering algorithm (see section~\ref{sec:calibration}). BIC enables the estimation of the BFs as $BF_{i,j} \approx e^{\frac{1}{2}(BIC_j - BIC_i)}$ yielding the relative support of each $\mathcal{M}_i$ against $\mathcal{M}_j$ \parencite{Schwarz:EstimatingDimensionModel:1978a,Burnham:MultimodelInferenceUnderstanding:2004}. 
 
  \paragraph{Likelyhood ratio tests} Since the set of models we consider here are nested, we additionally perform likelihood ratio tests (LR-tests) to determine the significance of incorporating additional transmission processes on top of the basic SIRB formulation. LR-tests were implemented by sequentially\footnotemark{} relaxing the constraint that the human-to-human and rainfall-related parameters are equal to 0 in \textbf{MN}. More particularly, we perform a LR-test for each pair of models $\{\mathcal{M}_0, \mathcal{M}_1\}$ who's parameter vectors $\boldsymbol{\theta}^0,\boldsymbol{\theta}^1$ take values from the set of all possible values in the parameter space $\Theta \subset \mathbb{R}^{n_p}$, for which at least on of the parameters that is not null is $\boldsymbol{\theta}^1$ is equal to 0 in $\boldsymbol{\theta}^0$, i.e.  $\boldsymbol{\theta}^0 \in \Theta^0 \subset \Theta, \boldsymbol{\theta}^1 \in \Theta^1 \subset \Theta, \Theta^0 \subset \Theta^1 = \Theta \setminus \Theta^0$, with $\Theta^0 = \{ \boldsymbol{\theta} | \{\theta_1, \dots, \theta_p  \} \in \mathbb{R}^{n_p} \wedge \ \exists i \in \{1,\dots, p\} : \theta_i = 0 \} $.
%Taken including the Bayesian Information Criterion (BIC)~ and a the . BIC is a criterion which penalizes the best log-likelihood computed during calibration by the model complexity (in this case, the number of parameters $n_p$) thus allowing to compare models having different degrees of freedom. DIC is particularly suited for Bayesian model selection when using an \textsc{mcmc} approach. DIC considers the average ensemble deviance associated to the posterior trajectories and penalizes it by its variance. Finally the likelihood-ratio test (LR test) is a statistical test to evaluate if the increase of complexity among two nested models is convenient with respect to the improvement of the fit (increase of the log-likelihood).
%\end{multicols}




 \section{Control of epidemic, and modeling of control of epidemics}%Public-health decision making tools using models
%- Control of epidemic, and modeling of control of epidemics
%- Public-health decision making tools using models

\section{Case Study: spatially-explicit cholera model}
%The model is a variation of the SIR model introduced first by Kermack and McKendrick\cite{Kermack:ContributionMathematicalTheory:1927}, with additional compartments for the vaccinated individuals and the bacteria concentration in the environment.

%The model subdivides the area potentially concerned by the epidemic into $n$ sub-regions. The sub-regions, defined by political boundaries or geomorphological features (like watersheds\cite{Bertuzzo:ProbabilityExtinctionHaiti:2016}), are represented as connected nodes. The $n$ nodes represent $n$ human communities having population size $H_i$, $i=1,\dots, n$. 

%At time $t$ and for each node $i$, the individuals in the node can be grouped into six compartments:

%\begin{itemize}
%\item $S_i(t)$: susceptible individuals  have no immunity, and may enter in contact with the bacteria and become infected (symptomatic or not),
%\item $I_i(t)$: infected individual shed bacteria into the community reservoir,
%\item $R_i(t)$: recovered are temporally immune, and don't participate in disease transmission,
%\item $V^S_i(t)$: vaccinated susceptible,
%\item $V^I_i(t)$: vaccinated infected,
%\item $V^R_i(t)$: vaccinated recovered.
%\end{itemize}

%In addition, the model considers the bacterial concentration of \textit{V.~cholerae} in the water reservoir of the community, $B_i(t)$. The $n$ nodes are connected by both human mobility and pathogen transport through water.

%Individuals commute from node $i$ to node $j$ with probability $Q_{ij}$. Bacteria are transported along the river network from node $i$ to node $j$ with probability $P_{ij}$, as shown in Figure~\ref{fig:bertuzzo14_SIRB}.


%The cholera dynamics are described by the following set of coupled ordinary differential equations:
%\begin{eqnarray}
%\frac{dI_i}{dt} &=& \sigma F_i(t) S_i - (\gamma + \mu + \alpha) I_i \label{eq:I2}\\
%\frac{dR_i}{dt} &=& (1-\sigma) F_i(t) S_i + \gamma I_i - (\rho + \mu+\frac{\nu_i(t)}{S_i+R_i}) R_i \label{eq:R2}\\
%\frac{dV^S_i}{dt} &=& \nu_i(t) \frac{S_i}{S_i+R_i}-\mu V^S_i \label{eq:VS2}\\
%\frac{dV^I_i}{dt} &=& \sigma (1-\eta) F_i(t) V^S_i - (\gamma + \mu + \alpha) V^I_i \label{eq:VI2}\\
%\frac{dV^R_i}{dt} &=& \nu_i(t) \frac{R_i}{S_i+R_i} + (1-\sigma) (1-\eta) F_i(t) V^S_i + \gamma V^I_i - (\mu+\rho_v) V^R_i \label{eq:VR2}\\
%\frac{dB_i}{dt} &=& - \mu_B B_i +\frac{p}{W_i}\left[1 + \phi J_i(t) \right] \left((1-m)(I_i +V_i^I)+m \sum_{j=1}^n Q_{ij} (I_j +V_j^I)\right)- \nonumber \\
%&& l \left( B_i - \sum_{j=1}^n P_{ji} \frac{W_j}{W_i} B_j \right)
%\end{eqnarray}
%
%where the population~$H_i$ of each node is assumed to be at demographic equilibrium, thus $S_i=H_i-I_i-R_i-V_i^S-V_i^I-V_i^R$.

%The force of infection, i.e the rate at which individual enters in contact with the diseases, is written as:
%
%\begin{equation}
%F_i(t) = \beta \left[ (1 - m) \frac{B_i}{K + B_i} + m \sum_{j=1}^n Q_{ij} \frac{B_j}{K + B_j} \right].
%\label{force}
%\end{equation}

%The parameter~$\beta$ represents the maximum exposure rate, which may decrease in time due to awareness of the population on the cholera transmission factors\cite{Bertuzzo:ProbabilityExtinctionHaiti:2016}. The fraction $B_{i}/(K+B_{i})$ is the probability of becoming infected due to the exposure to a concentration~$B_i$ of \textit{V.~cholerae}, $K$ being the half-saturation constant\cite{Codeco:EndemicEpidemicDynamics:2001}. The force of infection in a given node depends for a fraction ($1-m$) to the local concentration of \textit{V.~cholerae}, $B_i$, while the remaining fraction $m$, represents the community-level probability that individuals travel outside their node, accounts for the contribution of the concentration~$B_j$ of the remote communities. 
%The human mobility is accounted with the matrix $Q_{ij}$ representing the probabilities that an individual living in node $i$ reaches~$j$ as a destination. Because of human mobility, a susceptible individual residing at node $i$ can be exposed to pathogens in the destination community $j$. 
%In the lack of detailed mobility data,  the probabilities~$Q_{ij}$ can be estimated through a gravity approach\cite{erlander_gravity_1990} to model human mobility:
%
%\begin{equation}
%Q_{ij} = \frac{H_j e^{-d_{ij}/D}}{\sum_{k \neq i}^n H_k e^{-d_{ik}/D}} \, ,
%\label{eq:mob}
%\end{equation}
%where the attractiveness of node~$j$ depends on its population size $H_j$, while the deterrence factor is assumed to be dependent on the distance~$d_{ij}$ between the two communities via an exponential kernel (with shape factor~$D$).  

%Due to the contact with contaminated water, a fraction $\sigma$ of the infected individuals develops symptoms, passing from compartment $S$ to $I$. The remaining fraction~$(1-\sigma)$ does not develop symptoms, does not contribute to the disease transmission, and is considered temporally immune, thus passing from compartment $S$ to $R$.  Symptomatic infected individuals recover at a rate~$\gamma$, or die due to cholera or other causes at rates~$\alpha$ or $\mu$, respectively.
%Recovered individuals lose their immunity at rate~$\rho$, thus passing from compartments $R$ to $S$, or die at a rate~$\mu$.  % TODO Too many times property.

%The environmental concentration of \textit{V.~cholerae} at a node $i$ may increase due to both human mobility and to hydrologic dispersion. Human contributions depends from a fraction $1-m$ on the local infected individuals and form a fraction $m$ on the symptomatic infected individuals moving according to the mobility model. The increase in bacteria concentration is modeled with the rate~$p/W_i$, where $p$ is the rate at which bacteria excreted by an infected individual reach and contaminate the local water reservoir of volume $W_i$ (assumed to be proportional to population size, i.e., $W_i=c H_i$ as in\cite{Rinaldo:Reassessment20102011:2012}) and $\mu_B$ is the rate of decay of \textit{V.~cholerae}. Bacteria undergo hydrologic dispersal at a rate~$l$: pathogens travel from node~$i$ to~$j$ with probability $P_{ij}$, which is assumed to be one if node~$j$ is the downstream nearest neighborhood $i$, and zero otherwise. In order to express the worsening of sanitation conditions caused by rainfall-induced runoff, when relevant, which causes additional pathogen loads to enter the water reservoir due to effects such as the overflow of pit latrines and washout of open-air defecation sites\cite{Gaudart:SpatioTemporalDynamicsCholera:2013}, the contamination rate $p$ is increased by the rainfall intensity $J_i(t)$ via a coefficient $\phi$\cite{Rinaldo:Reassessment20102011:2012,righetto_rainfall_2013}. By introducing the dimensionless bacterial concentrations $B_i^*=B_i/K$,  it is possible to group three model parameters into a single ratio $\theta=p/(cK)$\cite{Bertuzzo:SpacetimeEvolutionCholera:2008}.



%The estimation of the local incidence is computed integrating over the new symptomatic individuals,
%
%\begin{equation}
%\frac{d C_i}{dt} \ = \ \sigma F_i S_i  \, , \label{eq:C}
%\end{equation}

%During the vaccination campaign, OCV doses are assumed to be distributed with rate $\nu_i(t)$ to susceptible and recovered individuals, which enter the compartments $V^S$ and $V^R$. As the OCV provides a partial immunity having efficacy $\eta$, $0\leq \eta \leq 1$, vaccinated susceptibles ($V^S$) can become infected ($V^I$) through a decreased force of infection of a factor $(1-\eta)$ with respect to non-vaccinated individuals. Vaccinated infected individuals behave exactly like infected ones, but are placed in a different compartment to exclude them from future vaccination campaigns. After recovering at  rate $\gamma$, they lose their vaccine protection at rate $\rho_{v}$.

\subsection{Optimal control}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% OK
\paragraph{Optimal Control Theory}
Optimal control theory describes the application of control variables to a system for the purpose of maximizing some measure of performance. The system is subject to its dynamics, with possible constraints on state and control variables. Let $\textbf{x}(t)$ be the state of a system at time $t$, and $\textbf{u}(t)$ be the control (or input) variable. 

In the general form, a continuous time optimal control problem (OCP) is written as the minimization of a cost functional $J$  with respect to the control variable $u(t)$:
\begin{equation}
\text{Minimize~~~} \min_{u(\cdot)} J=\Phi\,[\,\textbf{x}(t_0),t_0,\textbf{x}(t_f),t_f\,] + \int_{t_0}^{t_f} \mathcal{L}\,[\,\textbf{x}(t),\textbf{u}(t),t\,] \,dt
\end{equation}
subject to the system dynamics, path constraints and boundary conditions:
\begin{align}
\dot{\textbf{x}}(t) & =  \textbf{g}\,[\,\textbf{x}(t),\textbf{u}(t),t\,] \eqname{System dynamics}\\
\textbf{b}\,[\,\textbf{x}(t),\textbf{u}(t),t\,]  & \leq  \textbf{0} \eqname{Path constraints} \\
\boldsymbol{\phi}\,[\,\textbf{x}(t_0),t_0,\textbf{x}(t_f),t_f\,] & =  0 \eqname{Boundary conditions} 
\end{align}

The objective $J$ is the sum of the endpoint cost function $\Phi$ and the so called Lagrangian functional $\mathcal{L}$ that represent the cost along the path followed by the system.

The first constraints of the system are its dynamics, here a general ordinary differential equation $\textbf{g}$. In the case of cholera application, this is the spatially-explicit SIRB model. Path constraints $\textbf{b}$ in the form of inequalities are said inactive, and may be active when imposed as equalities. Finally, boundary conditions allow for forcing the system to end in a certain state, and to specify initial conditions.

Note that it is also possible to optimize the end time $t_f$. A simple change of variable transforms the OCP above into a free-end time problem. This possibility might result fundamental to optimize for the time of cholera extinction.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% OK
\paragraph{Solving an Optimal Control Problem}
Solving an OCP is a difficult task, but it  has received large attention during the cold war to guide rockets and missiles. Except for simple problems, like the linear quadratic  control, OCPs do not have analytical solutions and numerical solutions are typically sought. We highlight here two general methods for solving OCPs:

\par Indirect methods (or ``optimize then discretize'') use the calculus of variation to obtain first-order optimal conditions. The OCP is transformed in a multi-point boundary value problem (BVP) that has the form of a Hamiltonian system. Pontryagin's maximum principle guarantees the optimality of the solution. While this solution is elegant, the BVP may be difficult to solve and recently, direct methods are frequently preferred in applications.

\par The rational behind direct (or ``discretize then optimized'') methods is that a nonlinear programming (NLP) optimization problem with large dimension (tenth of thousand variables) has an easier numerical solution than a simple BVP, because it is sparse. That is, we rewrite our OCP (in the infinite dimensional functional space) into an optimization NLP (in a finite dimensional Euclidean space). 

In short, state and control variables are approximated (e.g using a piece-wise constant function) and the cost functional becomes a cost function. The problem is now to find the coefficients defining the control variable approximation, in such a way that they minimize the approximated cost function $F$. This leads to the following NLP:
\begin{equation}
\min_{\textbf{x} \in \mathbb{R}^n} F(\textbf{x})
\end{equation}
subject to:
\begin{equation}
g(\textbf{x}) = 0
\end{equation}    
\begin{equation}
h(\textbf{x}) \leq 0
\end{equation}
This problem is solved by any NLP solver, like Ipopt~\cite{wachter_implementation_2006}.   Optimal control toolboxes, like CasADI~\cite{andersson_casadi:_2012}, allow us to transform the symbolic formulation of the OCP in into an NLP. 

Despite a wide range of power tools, solving even a simple  optimal control problem is still a computationally-intensive task.

\paragraph{Epidemiological Applications of Optimal Control}

Optimal control is of great interest for practitioners and policy makers: it allows to formally back up existing policies, and may suggest alternative action plans. Indeed, such discoveries have to be carefully analyzed in order to be understood, as they might be due to model features. We present a brief literature review of studies on optimal control for epidemiological applications. This non-exhaustive review should present a sufficient picture of the current research landscape.

First, theoretical studies~\cite{kar_stability_2011, laguzet_global_2015} on  generic epidemiological models explored the feasibility and features of optimal control polices. These studies, first by Morton and Wickwire~\cite{morton_optimal_1974}, Sethi and Staats~\cite{sethi_optimal_1978}, Greenhalgh~\cite{greenhalgh_results_1988}, Behncke~\cite{behncke_optimal_2001} analyzed  various spatially-implicit models in a control system perspective, deriving existence, uniqueness, and stability of the optimal control for some (ideal) inputs like quarantine and vaccination.

It is also possible to use optimal control in order to find some general rules for disease intervention. For example, Rowthorn \textit{et al.}~\cite{rowthorn_optimal_2009} showed that for a system with two interconnected regions and a particular epidemic, equalizing infection in the two regions is the worst possible strategy in minimizing the total number of infection.

For cholera, intervention considered are a combination of antibiotics, vaccination and WaSH improvement. Tuite \textit{et al.} applied optimal control to the 2010 Haitian epidemic. For spatial allocation of the (rather small) vaccine stockpile available at that time, they compared optimal allocation against equal and density-dependent. They found that the later the vaccination is done, the better the optimal allocation performs against the control allocation strategies~\cite{tuite_cholera_2011}. However, there a few caveat in this study like the lack of inapparent infections~\cite{king_inapparent_2008, rinaldo_reassessment_2012}. Another approach was undertaken by Neilan \textit{et al.}~\cite{millerneilan_modeling_2010} in Calcutta and Bogra. They optimized for rehydratation/antibiotics, vaccination and sanitation, and concluded that a problem dependent mix of these methods is the most effective intevention strategy. This last approach and many others~\cite{sardar_optimal_2013} are designed for spatially-implicit models, and optimize the timing and proportion of the different interventions.

In an interesting theoretical study, Kelly Jr. \textit{et al.}~\cite{kelly_impact_2016} explored different mobility patterns and  optimal control intervention strategies. Namely, they tested a spatially-explicit version of the Tien and Earn model~\cite{tien_multiple_2010} and different spatial setups: nearest-neighbour connectivity, hub arrangement, and  hotspot map. They derived vaccination strategies. For example, one non-intuitive finding is that for nearest-neighbour connectivity, the outbreak patch should receive the least amount of effort.  A study by Chao \textit{et al.} compared different vaccination strategies using a spatially explicit model at small scale~\cite{chao_vaccination_2011}.  

Other cholera control analysis are either conceptual (no data nor a particular setup)~\cite{fister_optimal_2016} or do not search for an optimal control solution, but test the impact of different possible  strategies~\cite{kirpich_controlling_2017, eubank_modelling_2004, finger_potential_2018, seidlein_preventing_2018,azman_micro-hotspots_2018,lessler_mapping_2018,rebaudet_dry_2013}.

These studies are either theoretical, without connection to a particular setup nor actual data, or compare different control strategies defined by the author. In the framework of this thesis, I aim to develop a computational tool able to solve the optimal control problem for actual cholera outbreaks in quasi-real time, in order to provide objective information that can promptly support the health-care actors during the emergency. 
